# Optimization Methods Repository

This repository contains implementations and explanations of various optimization methods commonly used in mathematical optimization and machine learning. The implemented methods include Gradient Descent, Newton's Method, Lagrangian Optimization, Bisection, and more.

## Table of Contents

- [Introduction](#introduction)
- [Optimization Methods](#optimization-methods)
  - [Bisection Method](Bisection.py)
  - [Gradient Descent](Gradient.py)
  - [Newton raphson's Method](Newton_raph.py)
  - [Lagrangian Optimization](Lagrangian.py)
- [Usage](#usage)
- [Contributing](#contributing)
- [License](#license)

## Introduction

Optimization methods play a crucial role in various fields, including machine learning, mathematical modeling, and decision-making processes. This repository serves as a collection of implementations and explanations for several optimization algorithms.

## Optimization Methods

### Bisection Method

The Bisection Method is a simple numerical technique for finding the roots of a real-valued function within a given interval.

### Gradient Descent

The Gradient Descent method is an iterative optimization algorithm for finding the minimum of a function. It is widely used in machine learning for training models.

### Newton's Method

Newton's Method is an iterative root-finding algorithm that converges quickly to the roots of a real-valued function.

### Lagrangian Optimization

Lagrangian Optimization involves maximizing or minimizing a function subject to equality constraints. It is commonly used in constrained optimization problems.

## Usage

To use the implementations in this repository, follow the instructions in each method's respective directory. Ensure you have the necessary dependencies installed.

```bash
# Example command for running Gradient Descent
python gradient_descent.py
